<?xml version="1.0" encoding="utf-8"?>
<!--Copyright Â© 2026 Sanjyot Dahale.-->
<root xmlns:android="http://schemas.android.com/apk/res/android">
	<baseBuildGradleAdditions>
		<insert>
			allprojects {
			repositories {
			google()
			mavenCentral()
			}
			}
		</insert>
	</baseBuildGradleAdditions>

	<buildGradleAdditions>
		<insert>
      dependencies {
      implementation 'com.google.ai.edge.litertlm:litertlm-android:latest.release'
      implementation 'org.jetbrains.kotlin:kotlin-stdlib:1.9.20'
      implementation 'org.jetbrains:annotations:24.0.0'
      implementation 'com.google.guava:guava:32.1.3-android'
      }
    </insert>
	</buildGradleAdditions>

	<androidManifestUpdates>
		<addElements tag="application">
			<uses-native-library android:name="libvndksupport.so" android:required="false"/>
			<uses-native-library android:name="libOpenCL.so" android:required="false"/>
		</addElements>
    <addPermission android:name="android.permission.RECORD_AUDIO" />
    <addElements tag="manifest">
      <queries>
        <intent>
          <action android:name="android.intent.action.RECOGNIZE_SPEECH" />
        </intent>
      </queries>
    </addElements>
	</androidManifestUpdates>

	<gameActivityImportAdditions>
		<insert>
      // LiteRTLM Includes
      import com.google.ai.edge.litertlm.Content;
      import com.google.ai.edge.litertlm.Message;

      // STT Includes
      import android.speech.RecognitionListener;
      import android.speech.RecognizerIntent;
      import android.speech.SpeechRecognizer;
      import android.content.Intent;
      import android.os.Bundle;
      import java.util.ArrayList;

    </insert>
	</gameActivityImportAdditions>

	<gameActivityClassAdditions>
		<insert>
      private com.google.ai.edge.litertlm.Engine lmEngine;
      private com.google.ai.edge.litertlm.Conversation lmConversation;
      private com.google.ai.edge.litertlm.Message lmMessage;

      // Native JNI method for tool execution
      public native String nativeOnToolExecution(String functionName, String args);

      class GenericUnrealTool implements com.google.ai.edge.litertlm.OpenApiTool {
      private String name;
      private String fullDescriptionJson;

      public GenericUnrealTool(String name, String descriptionJson) {
      this.name = name;
      this.fullDescriptionJson = descriptionJson;
      }

      @Override
      public String getToolDescriptionJsonString() {
      return fullDescriptionJson;
      }

      @Override
      public String execute(String paramsJsonString) {
      android.util.Log.d("LiteRT-LM", "Executing Tool: " + name + " with params: " + paramsJsonString);
      return nativeOnToolExecution(name, paramsJsonString);
      }
      }


      // Class fields to store config for reset
      private List&lt;Object&gt;
        _tools;
        private String _systemPrompt;

        public void AndroidThunkJava_InitWithFunctions(String modelPath) {
        try {
        com.google.ai.edge.litertlm.Backend gpu = com.google.ai.edge.litertlm.Backend.GPU;
        com.google.ai.edge.litertlm.Backend cpu = com.google.ai.edge.litertlm.Backend.CPU;

        com.google.ai.edge.litertlm.EngineConfig config = new com.google.ai.edge.litertlm.EngineConfig(
        modelPath,              // 1. String: Model Path
        cpu,                    // 2. Backend: Base Backend
        null,                   // 3. Backend: Prefill Backend
        null,                   // 4. Backend: Decode Backend
        1024,                   // 5. Integer: Max Context Length
        getCacheDir().getPath() // 6. String: Cache Directory Path
        );

        lmEngine = new com.google.ai.edge.litertlm.Engine(config);
        lmEngine.initialize();

        com.google.ai.edge.litertlm.SamplerConfig sampler = new com.google.ai.edge.litertlm.SamplerConfig(40, 0.95, 0.1, 128);

        // Define Tools
        _tools = new ArrayList&lt;&gt;();

      // Tool 1: move_ai_to_pin
      String t1 = "{\"name\": \"move_ai_to_pin\", \"description\": \"Move the AI NPC to a predefined location.\", \"parameters\": { \"type\": \"object\" } }";
      _tools.add(com.google.ai.edge.litertlm.ToolKt.tool(new GenericUnrealTool("move_ai_to_pin", t1)));

      // Tool 2: find_nearest_weapon
      String t2 = "{\"name\": \"find_nearest_weapon\", \"description\": \"Find the weapon nearest to the player\", \"parameters\": { \"type\": \"object\" } }";
      _tools.add(com.google.ai.edge.litertlm.ToolKt.tool(new GenericUnrealTool("find_nearest_weapon", t2)));

      // Tool 3: toggle_tod
      String t3 = "{\"name\": \"toggle_tod\", \"description\": \"Toggle between day and night time of day in the game\", \"parameters\": { \"type\": \"object\" } }";
      _tools.add(com.google.ai.edge.litertlm.ToolKt.tool(new GenericUnrealTool("toggle_tod", t3)));

      // Tool 4: teleport_player
      String t4 = "{\"name\": \"teleport_player\", \"description\": \"Teleports the player to a specified location.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"location_tag\": { \"type\": \"string\", \"enum\": [\"red\", \"green\", \"blue\"], \"description\": \"The location tag to teleport to.\" } }, \"required\": [\"location_tag\"] } }";
      _tools.add(com.google.ai.edge.litertlm.ToolKt.tool(new GenericUnrealTool("teleport_player", t4)));

      // Tool 5: find_weapon
      String t5 = "{\"name\": \"find_weapon\", \"description\": \"Find the weapon defined by the weapon_name parameter.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"weapon_name\": { \"type\": \"string\", \"enum\": [\"pistol\", \"rifle\", \"grenadelauncher\"], \"description\": \"The name of the weapon to find.\" } }, \"required\": [\"weapon_name\"] } }";
      _tools.add(com.google.ai.edge.litertlm.ToolKt.tool(new GenericUnrealTool("find_weapon", t5)));

      // Tool 6: change_weapon_color
      String t6 = "{\"name\": \"change_weapon_color\", \"description\": \"Change the color of the weapon held by the player.\", \"parameters\": { \"type\": \"object\", \"properties\": { \"color_name\": { \"type\": \"string\", \"enum\": [\"red\", \"green\", \"blue\", \"white\", \"black\", \"pink\", \"random\"], \"description\": \"The color to change the weapon to.\" } }, \"required\": [\"color_name\"] } }";
      _tools.add(com.google.ai.edge.litertlm.ToolKt.tool(new GenericUnrealTool("change_weapon_color", t6)));

      _systemPrompt = "You are a model that can do function calling with the following functions";

      com.google.ai.edge.litertlm.ConversationConfig convConfig = new com.google.ai.edge.litertlm.ConversationConfig(
      com.google.ai.edge.litertlm.Contents.Companion.of(_systemPrompt),
      java.util.Collections.emptyList(),
      _tools,
      sampler,
      null
      );

      lmConversation = lmEngine.createConversation(convConfig);

      android.util.Log.d("LiteRT-LM", "Engine and Conversation Initialized with Tools");

      } catch (Exception e) {
      android.util.Log.e("LiteRT-LM", "Initialization failed: " + e.getMessage());
      }
      }

      public String AndroidThunkJava_GenerateResponse(String prompt) {
      if (lmEngine == null || lmConversation == null) {
      return "Error: Engine not initialized";
      }

      try {
      com.google.ai.edge.litertlm.Message response = lmConversation.sendMessage(prompt);

      String aiResult = response.toString();

      return aiResult;
      } catch (Exception e) {
      return "Error during generation: " + e.getMessage();
      }
      }


      public String AndroidThunkJava_SubmitFunctionResult(String functionName, String resultJson) {
      // Deprecated: Results are now handled automatically via ToolManager execution cycle
      return "Tool execution handled internally";
      }

      public void AndroidThunkJava_ResetConversation() {
      if (lmConversation != null) {
      lmConversation.close();
      lmConversation = null;
      }

      try {
      if (lmEngine != null &amp;&amp; _tools != null) {
      com.google.ai.edge.litertlm.SamplerConfig sampler = new com.google.ai.edge.litertlm.SamplerConfig(40, 0.95, 0.1, 128);

      com.google.ai.edge.litertlm.ConversationConfig convConfig = new com.google.ai.edge.litertlm.ConversationConfig(
      com.google.ai.edge.litertlm.Contents.Companion.of(_systemPrompt),
      java.util.Collections.emptyList(),
      _tools,
      sampler,
      null
      );
      lmConversation = lmEngine.createConversation(convConfig);
      android.util.Log.d("LiteRT-LM", "Conversation Reset Successfully");
      }
      } catch(Exception e) {
      android.util.Log.e("LiteRT-LM", "Reset Conversation Failed: " + e.getMessage());
      }
      }

      public void AndroidThunkJava_CloseConnection() {
      if (lmEngine != null || lmConversation != null) {
      lmEngine.close();
      lmConversation.close();
      }

      }


      private String copyAssetToInternal(String fileName) {
      java.io.File file = new java.io.File(getFilesDir(), fileName);
      if (!file.exists()) {
      try (java.io.InputStream is = getAssets().open(fileName);
      java.io.OutputStream os = new java.io.FileOutputStream(file)) {
      byte[] buffer = new byte[1024];
      int length;
      while ((length = is.read(buffer)) > 0) {
      os.write(buffer, 0, length);
      }
      android.util.Log.d("LiteRT-LM", "Model copied to: " + file.getAbsolutePath());
      } catch (java.io.IOException e) {
      android.util.Log.e("LiteRT-LM", "Failed to copy asset: " + e.getMessage());
      return null;
      }
      }
      return file.getAbsolutePath();
      }

      public void AndroidThunkJava_InitWithAssetName(String assetName) {
      String internalPath = copyAssetToInternal(assetName);
      if (internalPath != null) {
      AndroidThunkJava_InitWithFunctions(internalPath);
      }
      }

      public void AndroidThunkJava_ShutdownAll() {
      _activity.runOnUiThread(new Runnable() {
      @Override
      public void run() {
      // 2. Shutdown LiteRT-LM (using your existing CloseConnection logic)
      if (lmEngine != null) {
      lmEngine.close();
      lmEngine = null;
      }
      if (lmConversation != null) {
      lmConversation.close();
      lmConversation = null;
      }

      if (speechRecognizer != null) {
      speechRecognizer.stopListening();
      speechRecognizer.cancel();
      speechRecognizer.destroy();
      speechRecognizer = null;
      }

      android.util.Log.d("GemmaVR", "All AI services safely shutdown.");
      }
      });
      }

      private SpeechRecognizer speechRecognizer;
      private Intent recognizerIntent;

      // Native declaration to send text back to C++
      public native void nativeOnSTTResult(String text);

      public void AndroidThunkJava_InitSTT() {
      _activity.runOnUiThread(new Runnable() {
      @Override
      public void run() {
      speechRecognizer = SpeechRecognizer.createSpeechRecognizer(_activity);
      recognizerIntent = new Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH);
      recognizerIntent.putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM);
      // Use this to get results as soon as the user stops talking
      recognizerIntent.putExtra(RecognizerIntent.EXTRA_PARTIAL_RESULTS, false);

      speechRecognizer.setRecognitionListener(new RecognitionListener() {
      @Override
      public void onResults(Bundle results) {
      ArrayList&lt;String&gt; matches = results.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION);
      if (matches != null &amp;&amp; !matches.isEmpty()) {
      // Call the native C++ method with the best match
      nativeOnSTTResult(matches.get(0));
      }
      }

      @Override public void onReadyForSpeech(Bundle params) { android.util.Log.d("LiteRT-STT", "Listening..."); }
      @Override public void onError(int error) { android.util.Log.e("LiteRT-STT", "Error code: " + error); }
      @Override public void onBeginningOfSpeech() {}
      @Override public void onRmsChanged(float rmsdB) {}
      @Override public void onBufferReceived(byte[] buffer) {}
      @Override public void onEndOfSpeech() {}
      @Override public void onPartialResults(Bundle partialResults) {}
      @Override public void onEvent(int eventType, Bundle params) {}
      });
      }
      });
      }

      public void AndroidThunkJava_StartListening() {
      _activity.runOnUiThread(new Runnable() {
      @Override
      public void run() {
      if (speechRecognizer != null) {
      speechRecognizer.startListening(recognizerIntent);
      }
      }
      });
      }

      public void AndroidThunkJava_StopListening() {
      _activity.runOnUiThread(new Runnable() {
      @Override
      public void run() {
      if (speechRecognizer != null) {
      speechRecognizer.stopListening();
      }
      }
      });
      }

    </insert>
	</gameActivityClassAdditions>
</root>